{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Delete duplicate image assets within collections ###\n",
    "import ee, re\n",
    "from collections import Counter\n",
    "ee.Initialize()\n",
    "\n",
    "# CHANGE HERE\n",
    "root_name = \"projects/p79amhara3/assets/PS_imgs/79_Amhara_3/\" \n",
    "#root_name = \"projects/yieldpredug/assets/images/\"\n",
    "unique_matches = set()\n",
    "# CHANGE HERE\n",
    "locs =['lon10_959lat36_5095', 'lon10_9819lat39_2804', 'lon11_232lat39_0631', 'lon11_2599lat36_8433', 'lon11_2756lat39_545', 'lon12_4805lat37_4768', 'lon12_5496lat37_0654', 'lon9_8471lat39_7592', 'lon11_7375lat39_0025', 'lon11_8429lat39_7398', 'lon11_8729lat39_2944', 'lon10_5993lat39_9215', 'lon12_1201lat38_0486', 'lon9_9101lat40_0158', 'lon11_3993lat38_2379', 'lon11_4144lat37_9601', 'lon11_602lat37_946', 'lon12_1651lat38_8403', 'lon12_4289lat38_7151', 'lon11_4581lat38_9063']\n",
    "toApp=[]\n",
    "for loc in locs:\n",
    "    folder_name = root_name +loc\n",
    "    asset_list = ee.data.getList({'id': folder_name})\n",
    "    id_list = [item['id'] for item in asset_list]\n",
    "    for asset in id_list:\n",
    "        assetID = asset.replace(folder_name, \"\").replace('/','')\n",
    "        match = re.search(r'^(.*?)_Analytic', assetID)\n",
    "        if match:\n",
    "            match_str = match.group(1)\n",
    "            unique_matches.add(match_str)\n",
    "            toApp.append(match_str)\n",
    "\n",
    "    duplicates = [match for match in list(unique_matches) if sum(1 for id_item in id_list if match in id_item) > 1]\n",
    "    # Print the duplicates\n",
    "    print(\"Duplicates of the string before '_Analytic':\", len(duplicates), loc)    \n",
    "    for duplicate in sorted(duplicates):\n",
    "        # list all assets with this ID\n",
    "        result = [item for item in id_list if duplicate in item]\n",
    "        for res in result[1:]: # delete the second result and onwards\n",
    "            ee.data.deleteAsset(res)\n",
    "            #print(f'deleted asset {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Access data on planet orders; paste order ID from planet dashboard\n",
    "https://api.planet.com/compute/ops/orders/v2/cfd86736-ac14-4cd5-812e-96b8b88de38e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new service account credentials # makes for faster Planet delivery\n",
    "!base64  \"<xxx>_service_account_key.json\" > anna_service_account_key_encoded.txt # download from GCP, IAM roles\n",
    "print('here')\n",
    "import ee\n",
    "service_account = '<xxx>-service-account@<gcp name>.iam.gserviceaccount.com'\n",
    "credentials = ee.ServiceAccountCredentials(service_account, '<xxx>_service_account_key.json')\n",
    "ee.Initialize(credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all locs in a locgroup\n",
    "import json\n",
    "from google.cloud import storage\n",
    "storage_client = storage.Client()\n",
    "bucketName='<BUCKETNAME>'\n",
    "bucket=storage_client.get_bucket(bucketName)\n",
    "locGroup = \"<LOCGROUP>\"\n",
    "data_string=bucket.get_blob('{}/{}.geojson'.format(locGroup, locGroup)).download_as_string()\n",
    "data = json.loads(data_string)\n",
    "locList=[]\n",
    "for j in data['features']:\n",
    "    loc = j['properties']['mktID'].replace(\".\", \"_\", 2) #fix name format of mktID\n",
    "    dumped=json.dumps(j)\n",
    "    added='{\"type\": \"FeatureCollection\", \"features\": [{'+dumped[1:-1]+'}]}'\n",
    "    locList.append(loc) \n",
    "print(locList)\n",
    "formatted_string = ' '.join(locList)\n",
    "print(formatted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE NEW GCPs ###\n",
    "from google.cloud import storage\n",
    "import subprocess, json, time\n",
    "storage_client = storage.Client()\n",
    "\n",
    "def apply_iam_policy_with_backoff(project_id):\n",
    "    for attempt in range(5):\n",
    "        print(attempt)\n",
    "        try:\n",
    "            command = f\"gcloud projects set-iam-policy {project_id} ~/iam_policy.json\"\n",
    "            subprocess.run(command, check=True, input=\"Y\\n\",  shell=True, capture_output=True, text=True)\n",
    "            print(f\"IAM policy applied successfully to project {project_id}\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error applying IAM policy to project {project_id}. Attempt {attempt + 1}/5. Error message: {e}\")\n",
    "            time.sleep(1.2 ** attempt)\n",
    "    else:\n",
    "        print(f\"Failed to apply IAM policy to project {project_id} after 5 attempts.\")\n",
    "\n",
    "def createNewGCP(project_id):\n",
    "    for attempt in range(5):\n",
    "        print(attempt)\n",
    "        try:\n",
    "            command = f\"gcloud projects create {project_id} --name={project_id}\"\n",
    "            result =subprocess.run(command, check=True, shell=True,capture_output=True, text=True)\n",
    "            print(result.stdout)\n",
    "            print(f\"Successfully created GCP {project_id}\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error creating {project_id}. Attempt {attempt + 1}/5. Error message: {e}\")\n",
    "            time.sleep(1.2 ** attempt)\n",
    "    else:\n",
    "        print(f\"Failed to create {project_id} after 5 attempts.\")\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "def copy_file(source_bucket_name, source_blob_name, destination_blob_name):\n",
    "    \"\"\"Copies a file from one GCS bucket to another.\"\"\"\n",
    "    bucket = storage_client.bucket(source_bucket_name)\n",
    "    source_blob = bucket.blob(source_blob_name)\n",
    "    blob_copy = bucket.copy_blob(source_blob, bucket, destination_blob_name)\n",
    "    print(f\"File '{source_blob_name}' copied from '{source_bucket_name}' to '{bucket}' as '{destination_blob_name}'.\")\n",
    "\n",
    "        \n",
    "### Usage ###\n",
    "\n",
    "# If needing to generate a new iam_policy.json, delete the etag and version lines in it\n",
    "#gcloud projects get-iam-policy <GCP WITH CORRECT IAM ROLES> --format json >~/iam_policy.json\n",
    "\n",
    "\n",
    "gcpToCreate = [\"<<ENTER NAMES>>\"]\n",
    "for gcp in gcpToCreate:\n",
    "    command = f\"gcloud config set project planetupload\"\n",
    "    subprocess.run(command, check=True, shell=True)\n",
    "    gcpshort= 'p' + gcp.replace('_','',5).lower()\n",
    "    print(gcp, gcpshort)\n",
    "    copy_file('mai_2023', f'geojsonsToPutIntoFolders/{gcp}.geojson',\n",
    "              f'{gcp}/{gcp}.geojson')\n",
    "    createNewGCP(gcpshort)\n",
    "    apply_iam_policy_with_backoff(gcpshort)\n",
    "    command = f\"gcloud config set project {gcpshort}\"\n",
    "    subprocess.run(command, check=True, shell=True)\n",
    "    command = f\"gcloud services enable earthengine.googleapis.com\"\n",
    "    subprocess.run(command, check=True, shell=True)\n",
    "\n",
    "print('done')\n",
    "\n",
    "# Still need to click thru in GEE to register each project\n",
    "\n",
    "# (1) Create folder with name locGroup in planetupload/mai_2023\n",
    "# (2) Put geojson file of locGroup in that folder\n",
    "# (3) Create a new cloud project with the name lcoGroup\n",
    "# (4) Add that project to GEE\n",
    "# (5) Add 'planet-gee-uploader@planet-earthengine-staging.iam.gserviceaccount.com' as Earth Engine Resource Admin and Storage Admin in GCP \n",
    "# (6) create Master location file in 01_controller.ipynb\n",
    "# (7) Monitor planet orders to see whether they deliver correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE NEW MASTER LOCATION FILE ###\n",
    "import json, csv #, dropbox\n",
    "from google.cloud import storage\n",
    "\n",
    "bucketName='<BUCKET NAME>'\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket=storage_client.get_bucket(bucketName)\n",
    "\n",
    "### List here all location groups ###\n",
    "locGroups = ['<LOCGROUP>']\n",
    "#####################################\n",
    "for locGroup in locGroups:\n",
    "    with open('../masterLocationFile{}.csv'.format(locGroup), 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header row\n",
    "        csvwriter.writerow(['locGroup', 'Location', \"bucket\", \"00DownStatus\", \"00aDownNoSRStatus\",\"01PrepStarted\",\"01aPrepComplete\",\"01bPrepFailed\",\"02MapStarted\",\"02aMapComplete\",\"02bMapFailed\",\"03ActStarted\",\"03aActComplete\",\"03bActFailed\",\"04PropertiesDownload\"])\n",
    "\n",
    "        data_string = bucket.get_blob('{}/{}.geojson'.format(locGroup, locGroup)).download_as_string()\n",
    "        data_json = json.loads(data_string)\n",
    "        cc=0\n",
    "        for j in data_json['features']:\n",
    "            cc+=1\n",
    "            loc = j['properties']['mktID'].replace(\".\", \"_\", 2)\n",
    "            csvwriter.writerow([locGroup, loc,locGroup,\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"])\n",
    "                \n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
